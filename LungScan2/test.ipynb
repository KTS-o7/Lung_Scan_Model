{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the CT scan images\n",
    "data_dir = \"Path for CT scan images\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a list of all the CT scan images\n",
    "images = []\n",
    "for file in os.listdir(data_dir):\n",
    "  images.append(plt.imread(os.path.join(data_dir, file)))\n",
    "\n",
    "# Split the images into a training set and a testing set\n",
    "(train_images, test_images) = np.split(images, [int(len(images) * 0.8)])\n",
    "\n",
    "# Convert the images to grayscale\n",
    "train_images = np.array(train_images).astype(\"float32\") / 255.0\n",
    "test_images = np.array(test_images).astype(\"float32\") / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an instance of the CNN model\n",
    "model = CNN()\n",
    "\n",
    "# Compile the model\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(10):\n",
    "  for i, (images, labels) in enumerate(train_loader):\n",
    "    # Forward pass\n",
    "    outputs = model(images)\n",
    "\n",
    "    # Loss\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "      print(\"Epoch: {} Loss: {}\".format(epoch, loss.item()))\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  datasets.ImageFolder(data_dir, transform=transform),\n",
    "  batch_size=32,\n",
    "  shuffle=False\n",
    ")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for images, labels in test_loader:\n",
    "  outputs = model(images)\n",
    "  predicted = outputs.argmax(dim=1)\n",
    "  correct += (predicted == labels).sum().item()\n",
    "  total += len(labels)\n",
    "\n",
    "print(\"Accuracy: {}%\".format(100 * correct / total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the capability to mask the affected area and show it\n",
    "def mask_affected_area(image, prediction):\n",
    "  # Convert the prediction to a binary mask\n",
    "  mask = prediction > 0.5\n",
    "\n",
    "  # Mask the image\n",
    "  masked_image = image * mask\n",
    "\n",
    "  # Return the masked image\n",
    "  return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "# Load the pretrained model\n",
    "model = keras.models.load_model(\"path to load the image of the trained model/covid19_detection_model.h5\")\n",
    "\n",
    "# Predict the label for a CT scan image\n",
    "image = plt.imread(\"path for test image\")\n",
    "prediction = model.predict(image.reshape(1, 256, 256, 1))\n",
    "\n",
    "# Print the prediction\n",
    "print(prediction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
